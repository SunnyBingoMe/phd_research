% A simple template for Beamer presentations in LaTeX
% 
% To produce pdf run:
%   $ pdflatex beamer.tex 

\documentclass{beamer}
\usetheme{Singapore}

% Bibliography
%\usepackage{cite}
\usepackage{biblatex}


\hypersetup{colorlinks=true}

% Show table of contents between sections
\AtBeginSection[]
{
  \begin{frame}
    \frametitle{Table of Contents}
    \tableofcontents[currentsection]
  \end{frame}
}

% Graphics examples
%\centerline{\includegraphics[height=2.5in]{figs/normal.pdf}}
%\includegraphics[width=4in]{figs/makefile.png}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{Parallel Computing Through Code Analysis}
\date{\today}
\date{10 May 2017}
\author{Clark Fitzgerald}
\institute{UC Davis - Statistics Student Seminar}
\titlegraphic{\includegraphics[height=.5\textheight]{../workflow.pdf}}

\frame{\titlepage}

%\begin{frame}
%    \frametitle{Outline}
%    \tableofcontents
%\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Given sequential code and a description of data, the goal is to
    produce code which runs in parallel.}

\centerline{\includegraphics[width=.8\textwidth]{../workflow.pdf}}

\pause 

    \begin{itemize}
        \item R's user base consists of data analysts, domain scientists 
        \item Software engineering skill varies
    \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Motivating Example}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{The purpose of this example is to motivate the proposed research}

    \begin{itemize}
        \item Working with Professor Michael Zhang from Civil Engineering
        \item Illustrates complexity when computing with larger data sets
    \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Loop detectors count cars, measuring velocity and
    occupancy}

\centerline{\includegraphics[height=2.5in]{loop_detector.jpg}}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

\frametitle{Caltrans Performance Measurement System (PeMS) records this
data for the whole state}

    \begin{itemize}
        \item Each sensor measures 3 quantities
        \item Data point every 30 seconds
        \item $43,680$ sensors in California
        \item $\implies$  377 million data points per day
    \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Traffic engineers study the relationships between count and
    occupancy}
    %\cite{li2011fundamental}

\centerline{\includegraphics[height=2.5in]{fundamental_diagram.png}}

This shows 1 day for 1 station.

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Using more data allows new types of analyses}

    % Policy is especially interesting, because that can potentially be changed
    % Recommending state wide policy, then why not look at data for the
    % whole state?

    We can fit lines in parallel among different stations.

    \begin{itemize}
        \item Effect of policy such as speed limits and carpool lanes
        \item Impact of road features such as on/off ramps
        \item Effect of weather
        \item Clustering detectors
    \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{R expresses statistical computation well}

% This is a good reason to stay with R

    % Fork() avoids having to 

\centerline{\includegraphics[height=1in]{fundamental_diagram.png}}

\begin{verbatim}
by(data=single_day, INDICES = station, FUN = my_rlm)
\end{verbatim}

    \begin{itemize}
        \item For a single day with 377 million observations this can be
            done on a single machine.
        \item A sensible way to run this in parallel is to \texttt{fork()}
            the process after reading in the data.
        \item So you write a bunch of code to do that :)
    \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{But small changes can totally change the
    computation}

    If we compute on one year then this will exceed memory.

\begin{verbatim}
by(data=one_year, INDICES = station, FUN = my_rlm)
\end{verbatim}

\pause 

    A different model, such as least squares, may be able to process the
    data as a stream.

\begin{verbatim}
by(data=one_year, INDICES = station, FUN = my_lm)
\end{verbatim}

\pause 

    Adding in another variable, say weather condition, changes everything
    once again.

\begin{verbatim}
by(data=one_year, INDICES = list(station, weather),
    FUN = my_rlm)
\end{verbatim}

%\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{frame}
%
%    \frametitle{Lets scale up the computations with parallel programming}
%
%    \begin{itemize}
%        \item Several parallel strategies exist to improve performance
%        \item Which is best depends on the platform and data
%        \item Each one requires deeper knowledge of that particular technology
%        \item Therefore techniques to programmatically identify and use the parallel
%  patterns implicit in code would be valuable
%    \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Parallel Concepts}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

\frametitle{This example is to show how one might transform code.}

Consider computing the mean,

\begin{equation}
    \bar{x} = \frac{1}{n} \sum_{i = 1}^n x_i
\label{eq:mean}
\end{equation}

where the $x_i$'s are i.i.d. $\sim N(0, 1)$. 
    
In R this code is written:

\begin{verbatim}
xbar = mean(rnorm(n))
\end{verbatim}

% Explain what this does and how it fails.

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{This can also be expressed as a weighted mean}

\begin{equation}
    \bar{x} = \frac{1}{n} \sum_{j = 1}^p \sum_{i = 1}^{n_j} x_{ij}
    = \sum_{j = 1}^p \frac{n_j}{n} \bar{x}_j
\label{eq:mean_partial}
\end{equation}

Suppose that all $n_j$'s are the same for the following examples, so $n =
    n_j p$ and the equation becomes $\frac{1}{p} \sum_{j = 1}^p \bar{x}_j$

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{The weighted mean can be directly translated into R code}

\begin{verbatim}

partial_means = replicate(p, mean(rnorm(n_j)))
xbar = mean(partial_means)

\end{verbatim}

\pause 

    \begin{itemize}
        \item While not parallel, this effectively removes the memory limits.
        \item How to choose the $n_j$ and $p$?
    \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{The same computation can be evaluated on many workers
    simultaneously}

\centerline{\includegraphics[height=2in]{../snow.pdf}}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{Here is one way to parallelize this code}

\begin{verbatim}
library(parallel)
p = detectCores()
n_j = n / p
cluster = makeCluster(p)
clusterExport(cluster, "n_j")
partial_means = unlist(
    clusterEvalQ(cluster, mean(rnorm(n_j))))
xbar = mean(partial_means)
\end{verbatim}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{We're considering a system that transforms expressions}

    Input:

\begin{verbatim}
xbar = mean(rnorm(n))
\end{verbatim}

    Output:

\begin{verbatim}
library(parallel)
p = detectCores()
n_j = n / p
cluster = makeCluster(p)
clusterExport(cluster, "n_j")
partial_means = unlist(
    clusterEvalQ(cluster, mean(rnorm(n_j))))
xbar = mean(partial_means)
\end{verbatim}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Code Analysis}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{(Code, Data, Platform) together determine the execution
    strategy}

\begin{figure}
            \includegraphics[width=1.4in]{code_screen.png}
            \hfill
            \includegraphics[width=1in]{database.png}
            \hfill
            \includegraphics[width=1.4in]{gpu.jpg}
\end{figure}

%    \begin{itemize}
%    \item \textbf{Code} script to be executed
%    \item \textbf{Data} in-memory, files, database, etc
%    \item \textbf{Platform} 4 core laptop, server with GPU, Spark cluster,
%        etc
%    \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{CodeDepends is a tool for analyzing code as a data
    structure.}

    % One should know how 

\begin{verbatim}
n <- 10
x <- rnorm(n)
n <- 100
print(x + n)
\end{verbatim}

\begin{figure}
            %\hfill
    \includegraphics[width=2in]{../../experiments/ast/ast.pdf}
            %\hfill
    \includegraphics[width=1.3in]{../../experiments/ast/codegraph.pdf}
            \hfill
\end{figure}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}


\frametitle{Is it worth it to go parallel?}

    \centerline{\includegraphics[height=2.5in]{../compute_times/overhead}}

% This has to be answered for every piece of code, every time

% If there wasn't any overhead, we would use it all the time for
    % everything.

% If you start up a process, you want to keep it around

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}


    \frametitle{Factors to consider}

\textbf{Parameters}
\begin{itemize}
    \item number of processor cores to use
    \item size of each chunk
    \item which functions to combine in one processing step
\end{itemize}

\textbf{Constraints}
\begin{itemize}
    \item number of cores available
    \item network bandwidth
    \item disk IO speed
    \item available memory
\end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Estimating time required for the map reduce paradigm with many workers}

    % TODO: Get Duncan's feedback
\begin{itemize}
    \item $w_i$ worker startup time
    \item $c(x_i)$ communication time to send $x_i$ and receive $f(x_i)$.
    \item $e(x_i)$ time to evaluate $f(x_i)$ on a worker.
\end{itemize}

Then we minimize
\[
    \max_{x_i} \left( w_i + c(x_i) + e(x_i) \right)
\]
for $x = (x_1, \dots, x_m)$, a partition of $x$ into chunks.

%\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{frame}
%
%    \frametitle{If we want to compute on out of memory data:}
%
%\begin{itemize}
%    \item $w$ worker startup time
%    \item $l$ latency in communication
%    \item $t(n_j)$ time to compute on $n_j$ elements
%    \item $m(n_j)$ memory required to compute on $n_j$ elements
%\end{itemize}
%
%Then we minimize
%\[
%    w + 2l + \max (t(n_j))
%\]
%such that 
%
%\begin{itemize}
%    \item $\sum n_j = n$ total data points
%\end{itemize}
%
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{Idiomatic R already expresses computation in a natural
    parallel way through ``apply'' functions.}

\begin{verbatim}
x = replicate(5, rnorm(n_j), simplify = FALSE)

partialmeans = lapply(x, mean)

by(data, INDICES = station, FUN = piecewise_rlm)
\end{verbatim}

%    Specifically: apply, lapply, sapply, tapply, by, mapply, Map, vapply,
%    replicate, outer

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Layers mark ways for users to write parallel code for one
    platform}

\begin{itemize}
    \item \textbf{User Layer}: foreach, future, partools, ddR, biganalytics, RevoScaleR
    \item \textbf{R layer}: SNOW, parallel, bigmemory, Rmpi
    \item \textbf{System Layer}: processes, *NIX fork(), memory maps, network sockets,
    MPI
\end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{How can we transform R code into a lower layer?}

\begin{itemize}
    \item \textbf{Plain old R code: \texttt{lapply(), sapply(), for(), \dots}}
\item User Layer: foreach, future, partools, ddR, biganalytics, RevoScaleR
\item R layer: SNOW, parallel, bigmemory, Rmpi
\item System Layer: processes, *NIX fork(), memory maps, network sockets,
    MPI
\end{itemize}

% Potentially we can transform to any of these layers

%\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{frame}
%
%   \frametitle{Preserving language semantics can be challenging.}
%
%    For example, R's dynamic lookups 
%
%\begin{verbatim}
%
%    f = function() 0
%    g = function() f() + 1
%    f = function() 10
%    g()                     # Returns 11!
%
%\end{verbatim}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Knowledge of the data allows us to generate more specialized code}

    \begin{itemize}

	\item File size
	\item Dimensions of table / matrix / array
	\item Column classes
	\item Randomized rows
	\item Sorted / grouped
	\item Possible values for factor
	\item Indexed
	\item Including sufficient statistics

    \end{itemize}


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{One challenge is how to properly abstract ``data''}

    Some options:

    \begin{itemize}
        \item Iterators of chunks as in R's \texttt{iterators} package
        \item ``file-like'' objects from *NIX
        \item Pick one serialization format, ie. CSV, feather
        \item Abstract parallel data structures
    \end{itemize}

    \pause

    \begin{itemize}
        \item Maintain custom metadata objects?
        \item Only focus on data frames / tables?
    \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{An iterator produces data on demand}

    \centerline{\includegraphics[height=1.6in]{../iterator.pdf}}

    \begin{itemize}
        \item Most flexible of the above options
        \item Natural in pipeline parallel model
        \item Operate well with high performance IO libraries
    \end{itemize}

    \pause

    \begin{itemize}
        \item Unfamiliar to R programmers
        \item Not ideal if you need the whole data set
    \end{itemize}


%\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{frame}
%
%    \frametitle{Map and reduce functions}
%
%    Let $f: x \rightarrow y$ and $x = O(n)$, a data structure with $O(n)$
%    elements.
%
%    \begin{itemize}
%        \item If $y$ is also $O(n)$ then we can call $f$ a \textbf{Map} function.
%
%        \item Example: $f(x) = 2x$ for $x \in R^n$.
%
%    % This is vectorization in R
%    
%        \item If $y$ is $O(1)$ then $f$ is a \textbf{Reduce} function.
%
%        \item Example: $f(x) = \sum_{i = 1}^n x_i$
%    \end{itemize}


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Compiled R code provides even more efficiency}

\begin{enumerate}
    \item Parallelization will complement efforts to compile R
    \item Compiled code potentially allows the use of shared memory threads
    \item May follow the OpenCL kernel model
\end{enumerate}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

%    \frametitle{Follow up on the sensor example}
%
%    Program should:
%
%\begin{enumerate}
%    \item Remove any observations it can
%    \item Reorganize files on disk based on station ID
%    \item Apply function to each station ID file
%\end{enumerate}
%
%\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{frame}

    \frametitle{We propose using (Code, Data, Platform) to determine a
    parallel execution strategy}

\begin{figure}
            \includegraphics[width=1.4in]{code_screen.png}
            \hfill
            \includegraphics[width=1in]{database.png}
            \hfill
            \includegraphics[width=1.4in]{gpu.jpg}
\end{figure}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Some support infrastructure is necessary}

\begin{itemize}
\item Profiling and microbenchmark to measure overhead
\item File sort from R
\end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Next Steps}

\begin{itemize}
    \item Build and prove an actual system
\item Large data sets are only interesting if they provide fresh insight
\item Combining statistical results with computational capabilities
\end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Acknowledgements}

\begin{itemize}
    \item Feedback from Professor Duncan Temple Lang, Henrik Bengsston, and Nick Ulle
    \item Professor Michael Zhang from Civil Engineering
    \item Data Science Institute Affiliates and statistics students for
        applications
\end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Questions?}
    \centerline{\includegraphics[height=2.5in]{../workflow.pdf}}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Additional Slides}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{More Applications}

    % TODO: Expand on each of these

\begin{itemize}
    \item Benford test on election campaign contribution data
        %\cite{tam2007breaking}
    \item Forest greenness satellite imagery (Andrew Latimer)
    \item Simulating spread of disease (Nistara Randhawa)
\end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{How do we detect if a function in R is vectorized, and in
    which arguments?}

    \texttt{rnorm()} is vectorized in the last two arguments, but
    semantically different for a vector in the first argument.

\begin{verbatim}
> rnorm(5, mean = c(1, 2), sd = c(2, 10, 200))
[1]   0.2134756  -4.1137221 256.0094734   0.4562226 -10.3855374
\end{verbatim}

It's all C Code.

\begin{verbatim}
> rnorm
function (n, mean = 0, sd = 1)
.Call(C_rnorm, n, mean, sd)
\end{verbatim}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{R in a database}

    Suppose we want to call the vectorized function $f()$. If $f()$ is
    available both in R and the database then we have two options:

\begin{verbatim}
    Option 1: Run f inside database, returning result
    
    dbGetQuery(con,"SELECT f(x) FROM mydata;")

    Option 2: First fetch x, then call f within R

    f(dbGetQuery(con,"SELECT x FROM mydata;"))
\end{verbatim}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{By ``programming on the language'' we can modify existing
    code.}

\begin{verbatim}
lapply_to_mclapply = function(expr)
{
    # Changes lapply to parallel::mclapply
    lapply = quote(parallel::mclapply)
    expr = force(expr)
    # Following Wickham's Advanced R book
    call = substitute(substitute(expr))
    eval(call)
}

> e1 = quote(xmeans <- lapply(x, mean))
> lapply_to_mclapply(e1)
xmeans <- parallel::mclapply(x, mean)
\end{verbatim}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{Pipeline parallelism is like a factory assembly line.}

\centerline{\includegraphics[width=\textwidth]{../pipeline.pdf}}

\begin{verbatim}
# Worker 1
x_chunk = rnorm(n_j)
serialize(x_chunk, worker2)


# Worker 2
x_chunk = unserialize(worker1)
partial_means[i] = mean(x_chunk)
\end{verbatim}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Simple row based sampling misses the important areas of high
    occupancy.}

    \centerline{\includegraphics[height=2.5in]{../../analysis/pems/occ_flow_with_sample.pdf}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{frame}
%\begin{frame}
%\frametitle{References}
%\printbibliography
%\end{frame}

\end{document}
